# CXR VL research group
We're a group of doctoral students from KAIST's AI Graduate School, and we're all about multi-modal (vision-language) research in the medical field. 
Our aim is to continuously expand our knowledge and experience beyond traditional boundaries by deeply analyzing the essence of AI and the unique characteristics of the medical domain.

Every Thursday, we get together to review papers on the multi-modal research conducted in both general and medical fields, actively exploring the endless possibilities of AI through analysis and discussion. 
If you're interested in our study, especially if you have a background in medical or AI fields, we'd love for you to join us and grow together. (contact: jhak.moon@kaist.ac.kr)


KAIST AI 대학원의 박사과정 학생으로 구성된 우리 그룹은 의료 분야의 멀티모달(시각-언어) 연구에 전념하고 있습니다. 
인공지능의 본질과 의료 도메인의 특성을 깊이 연구하면서, 기존의 경계를 초월하여 우리의 지식과 경험을 지속적으로 확장하고자 합니다.

우리 그룹은 일반 분야와 의료 분야에서 진행되는 멀티모달 연구의 논문을 매주 선정하여 리뷰하며, 분석과 토론을 통해 인공지능의 끊임없는 가능성을 적극 탐구하고 있습니다.
우리 스터디에 관심 있으신 분, 특히 의료 (meidcal doctor) 또는 AI 분야의 배경을 가진 분은 언제든지 우리 그룹에 참여해 함께 성장하길 바랍니다. (contact: jhak.moon@kaist.ac.kr)

We will upload a recorded video on personal youtube storage. please check the link below.


Objective: 
Paper reading/discussion on VL models (not limited to md (medical domain);  md -> gd (general domain) -> md -> gd ...)


Time: 
Thur 10:30 AM - 11:30 AM

Agenda: 
1 people present for about 40 min / the rest is the discussion.


Participants : 
(KAIST-Edlab) 종학, 현경, 성수, (KAIST-MLIlab) 한결

Presentation Order:
종학 -> 현경 -> 한결 -> 성수


## **Paper List**:

|       Publish    | AKA | Paper | Topic | TL;DR |Link |  Review |
|:----------------:|:------:|:------:|:----------------------------------------:|:----------:|:------:|:------:|
| arxiv 23 / MS | BioViL-T | Learning to Exploit Temporal Structure for Biomedical Vision–Language Processing | parametric model | prior study, vision-language encoder, BERT-like decoder, VLM + LLM | [Paper](https://arxiv.org/pdf/2301.04558.pdf) | Jonghak (week1)  |
| CVPR 23 / HKUST | EPIC | Leveraging per Image-Token Consistency for Vision-Language Pre-training | . | CMLM, saliency based masking, inconsistent token generation and prediction task | [Paper](https://arxiv.org/pdf/2211.15398.pdf) | Hyungyung (week2) |
| arxiv 23 / Radboud University Medical Center | . | Medical diffusion on a budget: textual inversion for medical image generation | textual inversion | Stable Diffusion models can adapt to medical imaging modalities using textual inversion (100 samples) | [Paper](https://arxiv.org/abs/2303.13430) | Seongsu (week3) |

 




## **Paper-study**:


|       Date       | Week | Presenter |Topic |  Paper | Material | Link|
|:----------------:|:------:|:----------------------------------------:|:----------:|:------:|:------:|:------:|
| 2023.04.06 | Week01 | Jonghak | parametric model | BioViL-T | [Slides](https://docs.google.com/presentation/d/17VjF3-9yhSbvpwsgixYbZua13HhTP_Nkxb-JHRLqRBg/edit?usp=sharing) | |
| 2023.04.13 | Week02 | Hyungyung | Consistency based MLM | EPIC | [Slides](https://docs.google.com/presentation/d/1iy0Atqm-u3R-qyUaRvycpHg4YYx5XJ0FTVs3cTi6Yx4/edit?usp=sharing) | |
| 2023.04.20 | Week03 | Seongsu | textual inversion | . | None | |
| 2023.04.27 | Week04 | Jonghak | Zero convoluton | ControlNet | None | |
| 2023.05.04 | Week05 | Hyungyung | CXR Generation | Cheff | None | |
| 2023.05.11 | Week06 | Seongsu | PETL, Multimodal  | LLaMA-Adapter, -V2 | None | |
| 2023.05.18 | Week07 | Jonghak | Region-guided generation | RGRG | Slides | |
| 2023.05.25 | Week08 | Hyungyung | Compositionality | MosaiCLIP | None | |




